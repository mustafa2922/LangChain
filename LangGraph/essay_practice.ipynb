{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9688295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated\n",
    "from dotenv import load_dotenv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "feb21203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5f8ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8e9325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eval_schema(BaseModel):\n",
    "    feedback: str = Field(description='detailed feedback of essay covering all mistakes')\n",
    "    score: int = Field(description='score out of 10', ge=0 , le=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ddd74b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(Eval_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dea47f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Essay_state(TypedDict):\n",
    "\n",
    "    essay_text: str\n",
    "\n",
    "    lang_feedback: str\n",
    "    depth_feedback: str\n",
    "    clarity_feedback: str\n",
    "    relevance_feedback: str\n",
    "    evidence_feedback: str\n",
    "\n",
    "    overall_feedback: str\n",
    "    avg_score: float\n",
    "\n",
    "    scores: Annotated[list[float] , operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a5585c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lang(state:Essay_state) -> Essay_state:\n",
    "\n",
    "    template = PromptTemplate(\n",
    "        template='Evaluate the following essay for language quality. Comment on grammar, vocabulary, sentence structure, and tone. Give constructive feedback in 3–4 sentences. \\n text:{essay_text}',\n",
    "        input_variables=['essay_text']\n",
    "    )\n",
    "\n",
    "    prompt = template.invoke({'essay_text':state['essay_text']})\n",
    "    response = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'lang_feedback':response.feedback , 'scores':[response.score]}\n",
    "\n",
    "def eval_depth(state:Essay_state) -> Essay_state:\n",
    "\n",
    "    template = PromptTemplate(\n",
    "        template='Evaluate the following essay for depth of analysis. Does it show critical thinking, originality, and nuanced reasoning? Point out strengths and areas for improvement in 3–4 sentences. \\n text:{essay_text}',\n",
    "        input_variables=['essay_text']\n",
    "    )\n",
    "\n",
    "    prompt = template.invoke({'essay_text':state['essay_text']})\n",
    "    response = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'depth_feedback':response.feedback , 'scores':[response.score]}\n",
    "\n",
    "def eval_clarity(state:Essay_state) -> Essay_state:\n",
    "\n",
    "    template = PromptTemplate(\n",
    "        template='Evaluate the following essay for clarity. Focus on organization, logical flow, and ease of understanding. Provide specific feedback in 3–4 sentences. \\n text:{essay_text}',\n",
    "        input_variables=['essay_text']\n",
    "    )\n",
    "\n",
    "    prompt = template.invoke({'essay_text':state['essay_text']})\n",
    "    response = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'clarity_feedback':response.feedback , 'scores':[response.score]}\n",
    "\n",
    "def eval_relevance(state:Essay_state) -> Essay_state:\n",
    "\n",
    "    template = PromptTemplate(\n",
    "        template='Evaluate the following essay for relevance to the topic. Does it stay on point or deviate into unnecessary areas? Provide concise feedback in 3–4 sentences. \\n text:{essay_text}',\n",
    "        input_variables=['essay_text']\n",
    "    )\n",
    "\n",
    "    prompt = template.invoke({'essay_text':state['essay_text']})\n",
    "    response = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'relevance_feedback':response.feedback , 'scores':[response.score]}\n",
    "\n",
    "def eval_evidence(state:Essay_state) -> Essay_state:\n",
    "\n",
    "    template = PromptTemplate(\n",
    "        template='Evaluate the following essay for use of evidence. Does it support claims with examples, facts, or references? Suggest improvements in 3–4 sentences. \\n text:{essay_text}',\n",
    "        input_variables=['essay_text']\n",
    "    )\n",
    "\n",
    "    prompt = template.invoke({'essay_text':state['essay_text']})\n",
    "    response = structured_model.invoke(prompt)\n",
    "\n",
    "    return {'evidence_feedback':response.feedback , 'scores':[response.score]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f845e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_summary(state:Essay_state) -> Essay_state:\n",
    "\n",
    "    template = PromptTemplate(\n",
    "        template=\"Given the essay {essay_text} and the feedbacks [Language: {lang_feedback}; Depth: {depth_feedback}; Clarity: {clarity_feedback}; Relevance: {relevance_feedback}; Evidence: {evidence_feedback}], write a balanced 4–6 sentence summary feedback integrating all points without repeating the parameter names.\",\n",
    "        input_variables=['essay_text','lang_feedback','depth_feedback','clarity_feedback','relevance_feedback','evidence_feedback']\n",
    "    )\n",
    "    prompt = template.invoke({\n",
    "        'essay_text': state['essay_text'],\n",
    "        'lang_feedback': state['lang_feedback'],\n",
    "        'depth_feedback': state['depth_feedback'],\n",
    "        'clarity_feedback': state['clarity_feedback'],\n",
    "        'relevance_feedback': state['relevance_feedback'],\n",
    "        'evidence_feedback': state['evidence_feedback']\n",
    "    })\n",
    "\n",
    "    summary_feedback = model.invoke(prompt).content\n",
    "    avg_score = sum(state['scores']) / len(state['scores'])\n",
    "\n",
    "    return {'overall_feedback':summary_feedback, 'avg_score':avg_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdabb964",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(Essay_state)\n",
    "\n",
    "graph.add_node('eval_lang',eval_lang)\n",
    "graph.add_node('eval_depth',eval_depth)\n",
    "graph.add_node('eval_clarity',eval_clarity)\n",
    "graph.add_node('eval_relevance',eval_relevance)\n",
    "graph.add_node('eval_evidence',eval_evidence)\n",
    "graph.add_node('gen_summary',gen_summary) \n",
    "\n",
    "graph.add_edge(START,'eval_lang')\n",
    "graph.add_edge(START,'eval_depth')\n",
    "graph.add_edge(START,'eval_clarity')\n",
    "graph.add_edge(START,'eval_relevance')\n",
    "graph.add_edge(START,'eval_evidence')\n",
    "\n",
    "graph.add_edge('eval_lang','gen_summary')\n",
    "graph.add_edge('eval_depth','gen_summary')\n",
    "graph.add_edge('eval_clarity','gen_summary')\n",
    "graph.add_edge('eval_relevance','gen_summary')\n",
    "graph.add_edge('eval_evidence','gen_summary')\n",
    "\n",
    "graph.add_edge('gen_summary',END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11bd675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = \"\"\"The Importance of Critical Thinking in the Digital Age.\n",
    "We live in an age overflowing with information: newsfeeds, social media posts, opinion pieces, and instant commentary appear every second. This abundance brings huge benefits — easier access to learning, faster communication, and broadened perspectives — but it also creates new challenges. Chief among them is the need for strong critical thinking skills. Critical thinking helps people separate reliable information from noise, evaluate sources and arguments, and make decisions grounded in reason rather than impulse or popularity.\n",
    "A critical thinker questions assumptions instead of accepting them automatically. For example, when encountering a striking claim online, such a person will check the provenance of the claim, look for supporting evidence, and ask whether alternative explanations exist. This attitude reduces the spread of misinformation and prevents poor decisions that arise from incomplete or biased information. In academic and professional settings, critical thinking enables deeper analysis, better problem-solving, and more persuasive arguments — all crucial skills in competitive environments.\n",
    "Developing critical thinking also fosters intellectual humility. It encourages individuals to acknowledge the limits of their knowledge, seek diverse perspectives, and update beliefs when presented with better evidence. In polarizing environments, this habit promotes respectful dialogue and reduces echo chambers where ideas are blindly reinforced. Moreover, in practical terms, critical thinking improves everyday tasks: choosing trustworthy news sources, assessing product reviews, or understanding statistical claims in public policy debates.\n",
    "Education systems and workplaces should therefore emphasize reasoning, media literacy, and evidence-based discussion. Teaching students to evaluate arguments, interpret data, and construct clear justifications prepares them for civic life and the job market. Employers who value these skills gain teams that can adapt, innovate, and make sound decisions under uncertainty.\n",
    "In short, critical thinking is not an optional intellectual luxury — it is a practical necessity in the digital era. By cultivating skepticism tempered with openness, individuals can navigate information complexity, make informed choices, and contribute to healthier public discourse.\"\"\"\n",
    "\n",
    "essay = \"\"\"The moon is basically made of cheese and everyone knows that because cows jump over it in the nursery rhyme which is like basically evidence. Social media is the real school of life since scrolling teaches patience when WiFi is slow and anger management when it crashes. Teachers should be replaced with holograms of cats because cats are wise and mysterious, plus they never mark exams unfairly. Also, history is just a conspiracy by textbook companies who want to sell more paper, but digital tablets are spying on us through emojis. Critical thinking is overrated because if you think too much, you forget to vibe with the universe’s natural TikTok rhythms. In conclusion, life is like a sandwich: sometimes soggy, sometimes crunchy, but always confusing if you don’t put enough ketchup on it.\"\"\"\n",
    "\n",
    "\n",
    "initial_state = {\n",
    "    'essay_text':essay\n",
    "}\n",
    "\n",
    "output_state = workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2fa74647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'essay_text': 'The moon is basically made of cheese and everyone knows that because cows jump over it in the nursery rhyme which is like basically evidence. Social media is the real school of life since scrolling teaches patience when WiFi is slow and anger management when it crashes. Teachers should be replaced with holograms of cats because cats are wise and mysterious, plus they never mark exams unfairly. Also, history is just a conspiracy by textbook companies who want to sell more paper, but digital tablets are spying on us through emojis. Critical thinking is overrated because if you think too much, you forget to vibe with the universe’s natural TikTok rhythms. In conclusion, life is like a sandwich: sometimes soggy, sometimes crunchy, but always confusing if you don’t put enough ketchup on it.',\n",
       " 'lang_feedback': 'The essay contains frequent grammatical errors, such as missing articles and incorrect verb forms, which disrupt readability. Vocabulary choices are often informal or nonsensical, and the sentence structure is uneven, with many run‑on sentences and abrupt shifts in topic. The tone is overly casual and sometimes incoherent, making it hard to discern a clear argument. To improve, focus on consistent grammar, choose precise words, and organize ideas into coherent, well‑structured paragraphs.',\n",
       " 'depth_feedback': 'The essay is highly original in its whimsical premises, but it lacks depth of analysis and critical reasoning. It presents absurd claims (e.g., moon made of cheese, holographic cat teachers) without evidence or logical support, and it fails to engage with counterarguments or explore implications. The tone is playful, yet the arguments are superficial and do not demonstrate nuanced thinking or a structured argument. Strengths include creative language and a clear voice; improvement would come from grounding ideas in facts, developing coherent arguments, and addressing potential objections.',\n",
       " 'clarity_feedback': 'The essay jumps abruptly between unrelated ideas, making it hard to follow a coherent argument. The lack of transitions and clear topic sentences results in a disjointed structure that confuses readers. Additionally, the use of whimsical metaphors without grounding them in context weakens the overall clarity. A more organized outline with logical progression would greatly improve readability.',\n",
       " 'relevance_feedback': 'The essay drifts wildly across unrelated subjects—mythical moon cheese, social media habits, holographic cat teachers, textbook conspiracies, and TikTok vibes—without a clear central theme. It fails to maintain focus on any single topic, resulting in a disjointed narrative that confuses the reader. The lack of coherence makes it difficult to discern the author’s intended message or argument. Overall, the piece is off‑point and needs a tighter, more unified direction.',\n",
       " 'evidence_feedback': 'The essay largely lacks credible evidence to support its claims. Statements such as “the moon is made of cheese” or “teachers should be replaced with holograms of cats” are presented as facts without any references, data, or logical reasoning. The only “evidence” offered is a nursery rhyme and vague social‑media anecdotes, which do not substantiate the arguments. To improve, the writer should cite reputable sources (e.g., scientific studies, statistics, expert opinions) and explain how each example directly backs the claim. Additionally, distinguishing between opinion and evidence, and using concrete facts rather than metaphorical or humorous statements, would strengthen the essay’s persuasiveness.',\n",
       " 'overall_feedback': 'The essay’s playful voice and imaginative premises are engaging, yet the frequent grammatical mistakes and informal word choices hinder readability and weaken the overall impact. Its structure is fragmented, with abrupt topic shifts and a lack of clear transitions that make it difficult for readers to follow a coherent argument. While the originality shines through, the arguments remain shallow, lacking supporting evidence or logical reasoning, and they do not address potential counterpoints or explore deeper implications. The piece drifts across unrelated themes—moon cheese, social‑media habits, holographic cat teachers, textbook conspiracies—without a unifying focus, which dilutes its message. Strengthening the essay would involve tightening the language, organizing ideas into well‑structured paragraphs, grounding claims in credible sources, and developing a more focused, evidence‑based argument.',\n",
       " 'avg_score': 3.0,\n",
       " 'scores': [4, 3, 2, 4, 2]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
