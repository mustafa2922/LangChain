{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde56e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START , END\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5facd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f94ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(BaseModel):\n",
    "    sentiment: Literal['positive','negative']\n",
    "\n",
    "class Diagnosis(BaseModel):\n",
    "    issue_type: Literal[\"product_quality\", \"service\", \"delivery\", \"pricing\", \"support\", \"other\"] = Field(\n",
    "        ..., description=\"The main category of issue raised in the review.\"\n",
    "    )\n",
    "    tone: Literal[\"angry\", \"disappointed\", \"frustrated\", \"sarcastic\", \"neutral-negative\"] = Field(\n",
    "        ..., description=\"The emotional style of the review.\"\n",
    "    )\n",
    "    sentiment_strength: Literal[\"mild\", \"moderate\", \"strong\", \"extreme\"] = Field(\n",
    "        ..., description=\"The intensity of the negative sentiment.\"\n",
    "    )\n",
    "    specificity: Literal[\"vague\", \"somewhat_specific\", \"specific\"] = Field(\n",
    "        ..., description=\"How detailed and concrete the review is.\"\n",
    "    )\n",
    "    constructiveness: Literal[\"venting\", \"non_actionable\", \"actionable\"] = Field(\n",
    "        ..., description=\"Whether the review provides actionable feedback or just complaints.\"\n",
    "    )\n",
    "    authenticity: Literal[\"genuine\", \"spam\", \"troll\", \"biased\"] = Field(\n",
    "        ..., description=\"Whether the review appears authentic or suspicious.\"\n",
    "    )\n",
    "    politeness: Literal[\"polite\", \"neutral\", \"rude\"] = Field(\n",
    "        ..., description=\"The politeness or offensiveness of the review tone.\"\n",
    "    )\n",
    "    impact_severity: Literal[\"low\", \"medium\", \"high\"] = Field(\n",
    "        ..., description=\"How serious or impactful the issue raised in the review is.\"\n",
    "    )\n",
    "    improvement_suggestion: Literal[\"explicit\", \"implicit\", \"none\"] = Field(\n",
    "        ..., description=\"Whether the review suggests improvements explicitly, implicitly, or not at all.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de781eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_structured_model = model.with_structured_output(Sentiment)\n",
    "diagnosis_structured_model = model.with_structured_output(Diagnosis)\n",
    "\n",
    "sentiment_template = PromptTemplate(\n",
    "    template='Identify the sentiment of follwing review as positive or negative \\nReview: {review}',\n",
    "    input_variables=['review']\n",
    ")\n",
    "\n",
    "thanks_template = PromptTemplate(\n",
    "    template='Write a warm thank you message in response to this review \\nReview: {review}, \\nAlso ask user to leave feedback and rate us',\n",
    "    input_variables=['review']\n",
    ")\n",
    "\n",
    "diagnosis_template = PromptTemplate(\n",
    "    template='Analyze the review and return issue_type, tone, sentiment_strength, specificity, constructiveness, authenticity, politeness, impact_severity, improvement_suggestion. \\nReview: {review}',\n",
    "    input_variables=['review']\n",
    ")\n",
    "\n",
    "apology_template = PromptTemplate(\n",
    "    template= 'You are a customer support assistant; given the review \"{review}\" with issue_type={issue_type}, tone={tone}, sentiment_strength={sentiment_strength}, specificity={specificity}, constructiveness={constructiveness}, authenticity={authenticity}, politeness={politeness}, impact_severity={impact_severity}, and improvement_suggestion={improvement_suggestion}, write a short, empathetic, apology-themed response that acknowledges the problem and offers helpful next steps.',\n",
    "    input_variables = [\"review\", \"issue_type\", \"tone\", \"sentiment_strength\", \"specificity\", \"constructiveness\", \"authenticity\", \"politeness\", \"impact_severity\", \"improvement_suggestion\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e213cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review_State(TypedDict):\n",
    "\n",
    "    review: str\n",
    "    sentiment: Literal['positive','negative']\n",
    "    diagnosis:dict\n",
    "    response:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88145db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state:Review_State) -> Review_State:\n",
    "\n",
    "    prompt = sentiment_template.invoke({'review':state['review']})\n",
    "    sentiment = sentiment_structured_model.invoke(prompt).sentiment\n",
    "\n",
    "    return {'sentiment':sentiment}\n",
    "\n",
    "\n",
    "def run_diagnosis(state:Review_State) -> Review_State:\n",
    "        \n",
    "    prompt = diagnosis_template.invoke({'review':state['review']})\n",
    "    diagnosis_dict = diagnosis_structured_model.invoke(prompt).model_dump()\n",
    "\n",
    "    return {'diagnosis':diagnosis_dict}\n",
    "\n",
    "def thanks_msg(state:Review_State) -> Review_State:\n",
    "\n",
    "    prompt = thanks_template.invoke({'review':state['review']})\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return {'response':response.content}\n",
    "\n",
    "def apology_msg(state:Review_State) -> Review_State:\n",
    "\n",
    "    diagnosis = state['diagnosis']\n",
    "\n",
    "    prompt = apology_template.invoke({\n",
    "        \"review\": state[\"review\"],\n",
    "        \"issue_type\": diagnosis[\"issue_type\"],\n",
    "        \"tone\": diagnosis[\"tone\"],\n",
    "        \"sentiment_strength\": diagnosis[\"sentiment_strength\"],\n",
    "        \"specificity\": diagnosis[\"specificity\"],\n",
    "        \"constructiveness\": diagnosis[\"constructiveness\"],\n",
    "        \"authenticity\": diagnosis[\"authenticity\"],\n",
    "        \"politeness\": diagnosis[\"politeness\"],\n",
    "        \"impact_severity\": diagnosis[\"impact_severity\"],\n",
    "        \"improvement_suggestion\": diagnosis[\"improvement_suggestion\"],\n",
    "    })\n",
    "    \n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return {'response':response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27117cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_router(state:Review_State) -> Literal['thanks_msg','run_diagnosis']:\n",
    "\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'thanks_msg'\n",
    "    else:\n",
    "        return 'run_diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa0c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(Review_State)\n",
    "\n",
    "graph.add_node('find_sentiment',find_sentiment)\n",
    "graph.add_node('run_diagnosis',run_diagnosis)\n",
    "graph.add_node('thanks_msg',thanks_msg)\n",
    "graph.add_node('apology_msg',apology_msg)\n",
    "\n",
    "graph.add_edge(START,'find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment',conditional_router)\n",
    "\n",
    "graph.add_edge('thanks_msg',END)\n",
    "graph.add_edge('run_diagnosis','apology_msg')\n",
    "graph.add_edge('apology_msg',END)\n",
    "\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf6ac3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'fascinating UI, loves it, but performance requires some fixes',\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'product_quality',\n",
       "  'tone': 'disappointed',\n",
       "  'sentiment_strength': 'moderate',\n",
       "  'specificity': 'somewhat_specific',\n",
       "  'constructiveness': 'non_actionable',\n",
       "  'authenticity': 'genuine',\n",
       "  'politeness': 'polite',\n",
       "  'impact_severity': 'medium',\n",
       "  'improvement_suggestion': 'implicit'},\n",
       " 'response': 'We’re sorry to hear that the performance isn’t living up to the great UI you love.\\u202fWe understand how frustrating that can be.\\u202fIf you could share a bit more detail—such as the device you’re using, the app version, and any specific actions that feel slow—we’ll be able to investigate quickly. In the meantime, please try updating to the latest version (if you haven’t already) and clearing the app cache, which often helps. Feel free to reach out to our support team at\\u202fsupport@example.com\\u202fwith the details, and we’ll work on a fix for you as soon as possible. Thank you for bringing this to our attention.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {'review':'fascinating UI, loves it, but performance requires some fixes'}\n",
    "\n",
    "final_state = workflow.invoke(initial_state)\n",
    "final_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
